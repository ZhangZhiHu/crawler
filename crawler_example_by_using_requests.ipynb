{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./crawlerNotesFig/22.png)  \n",
    "This article is an example about how to login to a website by using python module Requests.Step by step,I make a detailed description about how to analyse the response and request.Moreover,first part also describes how to guess password by using a brute force crack method.By using a bottom-up approach,the process is clear and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the required packages\n",
    "import requests\n",
    "import cookielib\n",
    "import urllib2\n",
    "from pytesseract import pytesseract\n",
    "from PIL import Image\n",
    "import cStringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "username,password=open(r'C:\\account.txt').read().split('\\n') #read my username and password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,we need to start a session by using `requests.session()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session=requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,we need to use the first login page to get some cookies.Open the login page and open the developer tools we can see the page as follows:\n",
    "![](./crawlerNotesFig/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open the first file in developer tools named \n",
    ">'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'  \n",
    "\n",
    "the details are shown as:\n",
    "![](./crawlerNotesFig/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above,we know that the request method is 'GET',so `session.get()` is used.The request headers informations are also given in this figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url1=r'http://cas.whu.edu.cn/authserver/login?service=http://my.whu.edu.cn/'\n",
    "header1={\n",
    "    'Host':'cas.whu.edu.cn',\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://my.whu.edu.cn/'\n",
    "}\n",
    "\n",
    "r1=session.get(url1,headers=header1)\n",
    "print r1.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,we begin to analyse the login process.Be sure to tick the buttion of 'Enable persistent logs' in setting of developer tool,since,usually,if log is not perserved,the developer tool we only show the files loaded after login,that is,the process of login will be passed.Now,click the login button and use developer tool to monitor this process,we can find that a few new files haved been loaded.Open the one named \n",
    ">'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'.  \n",
    "\n",
    "![](./crawlerNotesFig/8.png)\n",
    "![](./crawlerNotesFig/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the headers we know its request method is 'POST',and there are also some infomations about the request headers.Now we check its params.The form data to post is here.It may be strange that the form data contains several other items besides username and password.However,tate it easy,these items can certainly be found in the files having been loaded.So,our next goal is to find the values of these 'strange items'.  \n",
    "![](./crawlerNotesFig/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request method is 'POST',so `session.post()` will be used.On the bottom,the form can be found.It is strange that the form data contains several other items besides username and password.However,take it easy,these items can certainly be found in the files having been loaded.So,in this situation,our goal is to find the values of 'lt','dllt','execution',and '_eventld'.  \n",
    "\n",
    "Next,we can copy one of the values in these items,for example.Suppose we have copied the value of lt,that is *'LT-1672447-NMdS9bi0sdGIcPQbbvunQSi2nkUczq1499734795811-mrXp-cas'*,now we open the response of the files prior *'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'*one by one to find the copied text.There is a trick that we can neglect several type files,such as png,script,gif and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CLTR+F to find the copied text in the 'page source' we have opened.We can find the copied text in the first file named*'\n",
    "login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'*.And the other 'strange items' are also here.\n",
    "![](./crawlerNotesFig/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So,before using `session.post()` to post the form data,we need to get the values of those 'strange items' by parsing the html of the file mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test whether the values are in the html\n",
    "'_eventId' in r1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LT-1824183-LlVwTM1liC2KfZ3fEmlez9RMishMeU1499745204808-iHnm-cas\n",
      "userNamePasswordLogin\n",
      "e1s1\n",
      "submit\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#parse the target values\n",
    "soup1=BeautifulSoup(r1.content,'lxml')\n",
    "form=soup1.find_all(\"form\",{'id':'casLoginForm'})[0]\n",
    "\n",
    "lt=form.find('input',{'name':'lt'})['value']\n",
    "dllt=form.find('input',{'name':'dllt'})['value']\n",
    "execution=form.find('input',{'name':'execution'})['value']\n",
    "_eventId=form.find('input',{'name':'_eventId'})['value']\n",
    "rmShown=form.find('input',{'name':'rmShown'})['value']\n",
    "print lt\n",
    "print dllt\n",
    "print execution\n",
    "print _eventId\n",
    "print rmShown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are all here.Now,let's post the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url2=r'http://cas.whu.edu.cn/authserver/login?service=http://my.whu.edu.cn/'\n",
    "header2={\n",
    "    'Host': 'cas.whu.edu.cn',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://cas.whu.edu.cn/authserver/login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "}\n",
    "\n",
    "postdata={'username':username,\n",
    "          'password':password,\n",
    "          'lt':lt,  #these items can be get from html\n",
    "          'dllt':dllt,\n",
    "          'execution':execution,\n",
    "          '_eventId':_eventId,\n",
    "          'rmShown':rmShown\n",
    "          }\n",
    "\n",
    "r2=session.post(url2,data=postdata,headers=header2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print r2.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year,it's right.We can now begin to crawl the data!  \n",
    "Checking the reponse of the files one by one,we find the data we want are all in the file named '/' as following:\n",
    "![](./crawlerNotesFig/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', error(10060, ''))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3e5627651858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mr3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    463\u001b[0m         }\n\u001b[0;32m    464\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;31m# Resolve redirects if allowed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# Shuffle things around if there's history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mresolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             )\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\requests\\adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', error(10060, ''))"
     ]
    }
   ],
   "source": [
    "url3='http://my.whu.edu.cn/'\n",
    "header3={\n",
    "    'Host':'my.whu.edu.cn',\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://cas.whu.edu.cn/authserver/login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "}\n",
    "\n",
    "r3=session.get(url3,headers=header3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is something wrong.Nevertheless,nothing to worry about.   \n",
    "***Several aspect:***  \n",
    "* **Is the request method right?***\n",
    "* ***Is there something missed in request headers?***\n",
    "* ***Is there typo error in url or request headers,and form data?***\n",
    "* ***Are the Request cookies right?***  \n",
    "\n",
    "\n",
    "Having made sure that there is no problem in the first three aspects,we begin to analyse the request cookies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's begin to analyse the cookies from the beginning.Focusing our attention on the 'Cookies' to find whether whether the 'Cookies' if different from those in the last file.If it is different,find whether there is an item named 'Set-Cookies' upward beginning from the last file.\n",
    "\n",
    "we can find the cookie is changed in file named *'?ticket=ST-376925-aOl7OVV6iBZnl1dQXYZk1499734811083-rvbW-cas'* and we can find the cookie is from the file named *'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'*\n",
    "![](./crawlerNotesFig/15.png)\n",
    "![](./crawlerNotesFig/16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cookies in '/',it is the same story.We can find the new cookies are from *'/?ticket=ST-376925-aOl7OVV6iBZnl1dQXYZk1499734811083-rvbW-cas'*.\n",
    "![](./crawlerNotesFig/17.png)\n",
    "![](./crawlerNotesFig/18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is clear that we can using a bottom-up method to analyse the crawling process.  \n",
    "\n",
    "To get the target data,we need get the html named  \n",
    ">'/'  \n",
    "\n",
    "and we need cookies to get it,so we have to get cookies from\n",
    ">'/?ticket=ST-376925-aOl7OVV6iBZnl1dQXYZk1499734811083-rvbW-cas'  \n",
    "\n",
    "then \n",
    ">'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F' and 'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'.  \n",
    "\n",
    "\n",
    "The codes are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import cookielib\n",
    "import urllib2\n",
    "from pytesseract import pytesseract\n",
    "from PIL import Image\n",
    "import cStringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "username,password=open(r'C:\\Python27\\zht\\whu\\account').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session=requests.session()\n",
    "\n",
    "url1=r'http://cas.whu.edu.cn/authserver/login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "headers1={\n",
    "    'Host':'cas.whu.edu.cn',\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0'\n",
    "    }\n",
    "r1=session.get(url1,headers=headers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parse form data from r1.content\n",
    "\n",
    "soup1=BeautifulSoup(r1.content,'lxml')\n",
    "form=soup1.find_all(\"form\",{'id':'casLoginForm'})[0]\n",
    "\n",
    "lt=form.find('input',{'name':'lt'})['value']\n",
    "dllt=form.find('input',{'name':'dllt'})['value']\n",
    "execution=form.find('input',{'name':'execution'})['value']\n",
    "_eventId=form.find('input',{'name':'_eventId'})['value']\n",
    "rmShown=form.find('input',{'name':'rmShown'})['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url2=r'http://cas.whu.edu.cn/authserver/login?service=http://my.whu.edu.cn/'\n",
    "header2={\n",
    "    'Host': 'cas.whu.edu.cn',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://cas.whu.edu.cn/authserver/login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "}\n",
    "\n",
    "postdata={'username':username,\n",
    "          'password':password,\n",
    "          'lt':lt,  #these items can be get from html\n",
    "          'dllt':dllt,\n",
    "          'execution':execution,\n",
    "          '_eventId':_eventId,\n",
    "          'rmShown':rmShown\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a trick that the url \n",
    ">'/?ticket=ST-376925-aOl7OVV6iBZnl1dQXYZk1499734811083-rvbW-cas'  \n",
    "\n",
    "is obviously a variable,we need to get it from the prior files.Usually,the path variable can be found as the value of 'Location',an item in the 'Response headers' of the prior files.It is not hard to find this variable in \n",
    ">'login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "\n",
    "![](./crawlerNotesFig/19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notice**  \n",
    "The [Location](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Location) item is a little special,to capture it,we need to set the parameter `allow_redirects` as `False` in `session.post()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content-length': '0', 'content-language': 'en-US', 'set-cookie': 'CASPRIVACY=\"\"; Expires=Thu, 01-Dec-94 16:00:00 GMT; Path=/authserver/, iPlanetDirectoryPro=AQIC5wM2LY4Sfczfkf90wbg%2FQ6uu8P%2BhX%2B%2FvNiK3fHFIMEU%3D%40AAJTSQACMDI%3D%23; Path=/; Domain=.whu.edu.cn, CASTGC=TGT-179849-ROlyAbYsIcZbtIpI1p5JelQYG3IW9YOJOi2NwZb435FqMQGMWr1499745762830-vcnA-cas; Path=/authserver/; HttpOnly', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'server': 'openresty', 'connection': 'keep-alive', 'location': 'http://my.whu.edu.cn/?ticket=ST-411531-dtjSVTM0qh1gmqSpSGIW1499745762873-jebj-cas', 'pragma': 'no-cache', 'cache-control': 'no-cache, no-store', 'date': 'Tue, 11 Jul 2017 04:02:42 GMT'}\n"
     ]
    }
   ],
   "source": [
    "r2=session.post(url2,data=postdata,headers=header2,allow_redirects=False)\n",
    "print r2.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,'Location' has been captured.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status_code is 302,which includes a location header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact,there is a indirection,so,from the initial url2 we can get no content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print r2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way,if we want to break the password,we can stop here and add a 'if-condition' to confirm whether or not we have found the true password.\n",
    "```python\n",
    "if r2.status_code==302:\n",
    "    print 'the password is right'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,get back on track and we begin to crawl the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#crawl the target data\n",
    "location=r2.headers['location']\n",
    "url3=location\n",
    "header3={\n",
    "    'Host': 'my.whu.edu.cn',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://cas.whu.edu.cn/authserver/login?service=http%3A%2F%2Fmy.whu.edu.cn%2F'\n",
    "}\n",
    "\n",
    "r3=session.get(url3,headers=header3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print r3.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So great! We have login successfully.  \n",
    "\n",
    "The remaining job is to parse the data.It is a little boring but necessary.Suppose we want to crawl the information encircled by the red line as below.\n",
    "![](./crawlerNotesFig/20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again,the url\n",
    "> /?.pn=p11972  \n",
    "\n",
    "is a variable.we can find it from the html of url\n",
    "> '/'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the target html\n",
    "soup3=BeautifulSoup(r3.content,'lxml')\n",
    "li=soup3.find('li',text='个人信息')\n",
    "\n",
    "urlInfo=r'http://my.whu.edu.cn/'+li.a['href']\n",
    "\n",
    "header4={\n",
    "    'Host': 'my.whu.edu.cn',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Referer':'http://my.whu.edu.cn/'\n",
    "}\n",
    "\n",
    "\n",
    "r4=session.get(urlInfo,headers=header4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r4.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,parse this html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup4=BeautifulSoup(r4.content)\n",
    "table=soup4.find('table',{'class':'pa-main-table'})\n",
    "\n",
    "\n",
    "text=table.text\n",
    "text1=text.strip()\n",
    "text2=text1.split('\\n\\n\\n')\n",
    "\n",
    "studentId=text2[0].split('\\n')[1].strip()\n",
    "name=text2[0].split('\\n')[3].strip()\n",
    "gender=text2[1].split('\\n')[1].strip()\n",
    "birthday=text2[1].split('\\n')[3].strip()\n",
    "nationality=text2[1].split('\\n')[5].strip()\n",
    "ploticalStatus=text2[2].split('\\n')[1].strip()\n",
    "idNumber=text2[2].split('\\n')[3].strip()\n",
    "grade=text2[3].split('\\n')[1].strip()\n",
    "category=text2[3].split('\\n')[3].strip()\n",
    "faculty=text2[3].split('\\n')[5].strip()\n",
    "major=text2[4].split('\\n')[1].strip()\n",
    "dormitory=text2[4].split('\\n')[3].strip()\n",
    "address=text2[4].split('\\n')[5].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "男\n",
      "共青团员\n",
      "经济与管理学院\n",
      "湖北省武汉市武昌区珞珈山街道武汉大学\n"
     ]
    }
   ],
   "source": [
    "print gender\n",
    "print ploticalStatus\n",
    "print faculty\n",
    "print address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=soup4.find('img',{'alt':'图片'})\n",
    "urlPic=r'http://my.whu.edu.cn/'+img['src']\n",
    "\n",
    "r5=session.get(urlPic)\n",
    "with open(username+'.png','wb') as f:\n",
    "    f.write(r5.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./crawlerNotesFig/21.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
